{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dccd46-690a-4329-b755-a728c95afd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Unit Agent Ready! Type a conversion question or 'exit' to quit.\n",
      "\n",
      "📊 Agent Flow Diagram:\n",
      "\n",
      "[classify]\n",
      "   |\n",
      "   v\n",
      "[route]\n",
      "\n",
      "[route]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Your question:  6inches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 [Unit Agent] Classifying tool for input: 6inches\n",
      "🧠 [Unit Agent] Selected tool: length_converter\n",
      "\n",
      "🔄 [Router] Routing to: length_converter\n",
      "\n",
      "🔧 [length_converter] Input: 6inches\n",
      "\n",
      "🧠 [Final Output]\n",
      "🔧 Selected Tool: length_converter\n",
      "✅ Result: Unit Error: Couldn't parse input\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Your question:  1 inch to cm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 [Unit Agent] Classifying tool for input: 1 inch to cm\n",
      "🧠 [Unit Agent] Selected tool: length_converter\n",
      "\n",
      "🔄 [Router] Routing to: length_converter\n",
      "\n",
      "🔧 [length_converter] Input: 1 inch to cm\n",
      "✅ [length_converter] Result: 1.0 inch = 2.54 cm\n",
      "\n",
      "🧠 [Final Output]\n",
      "🔧 Selected Tool: length_converter\n",
      "✅ Result: 1.0 inch = 2.54 cm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Dict, Callable, Optional\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Configure Gemini (replace dummy key)\n",
    "genai.configure(api_key=\"AIzaSyAo9E2DL9tEQcDAyQbWwf-5QVCriyU7jIQ\")\n",
    "\n",
    "LOG_FILE = \"unit_agent.log\"\n",
    "\n",
    "def log(message: str):\n",
    "    timestamp = datetime.datetime.now().isoformat()\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "# --- Modular Tools ---\n",
    "\n",
    "def length_converter(expr: str) -> str:\n",
    "    log(f\"\\n🔧 [length_converter] Input: {expr}\")\n",
    "    # Recognizes e.g. \"12 inches to cm\" or \"5.2 meters in feet\"\n",
    "    pattern = re.compile(r'([\\d.]+)\\s*(inches|inch|cm|centimeters|centimetres|meters|metres|feet|foot)\\s*(to|in)\\s*(inches|inch|cm|centimeters|centimetres|meters|metres|feet|foot)', re.I)\n",
    "    match = pattern.search(expr)\n",
    "    if not match:\n",
    "        return \"Unit Error: Couldn't parse input\"\n",
    "\n",
    "    value = float(match.group(1))\n",
    "    from_unit = match.group(2).lower()\n",
    "    to_unit = match.group(4).lower()\n",
    "\n",
    "    conversions = {\n",
    "        ('inches', 'cm'): lambda x: x * 2.54,\n",
    "        ('inch', 'cm'): lambda x: x * 2.54,\n",
    "        ('cm', 'inches'): lambda x: x / 2.54,\n",
    "        ('centimeters', 'inches'): lambda x: x / 2.54,\n",
    "        ('meters', 'feet'): lambda x: x * 3.28084,\n",
    "        ('metres', 'feet'): lambda x: x * 3.28084,\n",
    "        ('feet', 'meters'): lambda x: x / 3.28084,\n",
    "        ('foot', 'meters'): lambda x: x / 3.28084,\n",
    "    }\n",
    "    func = None\n",
    "    for (src, dst), f in conversions.items():\n",
    "        if src in from_unit and dst in to_unit:\n",
    "            func = f\n",
    "            break\n",
    "    if not func:\n",
    "        return \"Unit Error: Conversion not supported\"\n",
    "    result = func(value)\n",
    "    answer = f\"{value} {from_unit} = {round(result, 4)} {to_unit}\"\n",
    "    log(f\"✅ [length_converter] Result: {answer}\")\n",
    "    return answer\n",
    "\n",
    "def temperature_converter(expr: str) -> str:\n",
    "    log(f\"\\n🔧 [temperature_converter] Input: {expr}\")\n",
    "    match = re.search(r'([\\d\\.\\-]+)\\s*([cCfF])\\s*(to|in)\\s*([cCfF])', expr)\n",
    "    if not match:\n",
    "        return \"Unit Error: Couldn't parse temperature input\"\n",
    "    value = float(match.group(1))\n",
    "    from_unit = match.group(2).upper()\n",
    "    to_unit = match.group(4).upper()\n",
    "    if from_unit == to_unit:\n",
    "        return f\"{value}°{from_unit} = {value}°{to_unit}\"\n",
    "    if from_unit == \"C\" and to_unit == \"F\":\n",
    "        result = value * 9/5 + 32\n",
    "    elif from_unit == \"F\" and to_unit == \"C\":\n",
    "        result = (value - 32) * 5/9\n",
    "    else:\n",
    "        return \"Unit Error: Conversion not supported\"\n",
    "    answer = f\"{value}°{from_unit} = {round(result, 2)}°{to_unit}\"\n",
    "    log(f\"✅ [temperature_converter] Result: {answer}\")\n",
    "    return answer\n",
    "\n",
    "def weight_converter(expr: str) -> str:\n",
    "    log(f\"\\n🔧 [weight_converter] Input: {expr}\")\n",
    "    pattern = re.compile(r'([\\d.]+)\\s*(kg|kilograms|g|grams|lbs|pounds)\\s*(to|in)\\s*(kg|kilograms|g|grams|lbs|pounds)', re.I)\n",
    "    match = pattern.search(expr)\n",
    "    if not match:\n",
    "        return \"Unit Error: Couldn't parse input\"\n",
    "    value = float(match.group(1))\n",
    "    from_unit = match.group(2).lower()\n",
    "    to_unit = match.group(4).lower()\n",
    "\n",
    "    conversions = {\n",
    "        ('kg', 'lbs'): lambda x: x * 2.20462,\n",
    "        ('kilograms', 'pounds'): lambda x: x * 2.20462,\n",
    "        ('lbs', 'kg'): lambda x: x / 2.20462,\n",
    "        ('pounds', 'kg'): lambda x: x / 2.20462,\n",
    "        ('g', 'kg'): lambda x: x / 1000,\n",
    "        ('kg', 'g'): lambda x: x * 1000,\n",
    "    }\n",
    "    func = None\n",
    "    for (src, dst), f in conversions.items():\n",
    "        if src in from_unit and dst in to_unit:\n",
    "            func = f\n",
    "            break\n",
    "    if not func:\n",
    "        return \"Unit Error: Conversion not supported\"\n",
    "    result = func(value)\n",
    "    answer = f\"{value} {from_unit} = {round(result, 4)} {to_unit}\"\n",
    "    log(f\"✅ [weight_converter] Result: {answer}\")\n",
    "    return answer\n",
    "\n",
    "def fallback_tool(expr: str) -> str:\n",
    "    log(f\"\\n🔧 [fallback_tool] Using LLM fallback for: {expr}\")\n",
    "    prompt = f\"Answer or help with this unit conversion: {expr}\"\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "    response = model.generate_content(prompt).text.strip()\n",
    "    log(f\"✅ [fallback_tool] Result: {response}\")\n",
    "    return response\n",
    "\n",
    "TOOL_AGENTS: Dict[str, Callable[[str], str]] = {\n",
    "    \"length_converter\": length_converter,\n",
    "    \"temperature_converter\": temperature_converter,\n",
    "    \"weight_converter\": weight_converter,\n",
    "    \"fallback_tool\": fallback_tool,\n",
    "}\n",
    "\n",
    "# --- Agent State ---\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    tool_name: str\n",
    "    result: str\n",
    "    history: Optional[list[str]]\n",
    "\n",
    "# --- Classify tool (LLM) ---\n",
    "\n",
    "def classify_tool(state: AgentState) -> AgentState:\n",
    "    user_input = state['user_input']\n",
    "    history = state.get('history') or []\n",
    "    log(f\"\\n🔍 [Unit Agent] Classifying tool for input: {user_input}\")\n",
    "    history_text = \"\\n\".join(history[-5:])\n",
    "    prompt = f\"\"\"\n",
    "You are a tool selector agent.\n",
    "Decide which tool best matches the user's input.\n",
    "\n",
    "Available tools:\n",
    "- length_converter: for converting length units (\"12 inches to cm\", \"3 meters in feet\")\n",
    "- temperature_converter: for temperature (\"25 C to F\", \"100F to Celsius\")\n",
    "- weight_converter: for weight (\"80 kg to lbs\", \"200 grams in kilograms\")\n",
    "\n",
    "Only return one tool name exactly as shown.\n",
    "\n",
    "Conversation history:\n",
    "{history_text}\n",
    "\n",
    "Input: \"{user_input}\"\n",
    "Tool:\n",
    "\"\"\"\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "    tool_name = model.generate_content(prompt).text.strip()\n",
    "    if tool_name not in TOOL_AGENTS:\n",
    "        log(f\"⚠️ [Unit Agent] Invalid tool selected: {tool_name}, defaulting to fallback_tool\")\n",
    "        tool_name = \"fallback_tool\"\n",
    "    else:\n",
    "        log(f\"🧠 [Unit Agent] Selected tool: {tool_name}\")\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_name\": tool_name,\n",
    "        \"result\": \"\",\n",
    "        \"history\": history,\n",
    "    }\n",
    "\n",
    "# --- Run selected tool ---\n",
    "\n",
    "def run_selected_tool(state: AgentState) -> AgentState:\n",
    "    tool_name = state[\"tool_name\"]\n",
    "    user_input = state[\"user_input\"]\n",
    "    log(f\"\\n🔄 [Router] Routing to: {tool_name}\")\n",
    "    tool_fn = TOOL_AGENTS.get(tool_name)\n",
    "    if not tool_fn:\n",
    "        log(f\"⚠️ [Router] Unknown tool '{tool_name}', using fallback.\")\n",
    "        result = fallback_tool(user_input)\n",
    "    else:\n",
    "        result = tool_fn(user_input)\n",
    "    return {**state, \"result\": result}\n",
    "\n",
    "# --- Build Graph ---\n",
    "\n",
    "def build_unit_agent():\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"classify\", classify_tool)\n",
    "    graph.add_node(\"route\", run_selected_tool)\n",
    "    graph.set_entry_point(\"classify\")\n",
    "    graph.add_edge(\"classify\", \"route\")\n",
    "    graph.set_finish_point(\"route\")\n",
    "    print_flow_diagram([\"classify\", \"route\"], [(\"classify\", \"route\")])\n",
    "    return graph.compile()\n",
    "\n",
    "def print_flow_diagram(nodes, edges, delay=0.6):\n",
    "    print(\"\\n📊 Agent Flow Diagram:\\n\")\n",
    "    for node in nodes:\n",
    "        print(f\"[{node}]\")\n",
    "        time.sleep(delay)\n",
    "        next_nodes = [dst for src, dst in edges if src == node]\n",
    "        for nxt in next_nodes:\n",
    "            print(\"   |\")\n",
    "            time.sleep(delay / 2)\n",
    "            print(\"   v\")\n",
    "            time.sleep(delay / 2)\n",
    "            print(f\"[{nxt}]\")\n",
    "            time.sleep(delay)\n",
    "        print()\n",
    "\n",
    "# --- Main loop ---\n",
    "\n",
    "def unit_agent_loop():\n",
    "    history = []\n",
    "    log(\"\\n🤖 Unit Agent Ready! Type a conversion question or 'exit' to quit.\")\n",
    "    graph = build_unit_agent()\n",
    "    while True:\n",
    "        user_text = input(\"\\n💬 Your question: \").strip()\n",
    "        if user_text.lower() == \"exit\":\n",
    "            log(\"👋 Exiting Unit Agent. Goodbye!\")\n",
    "            break\n",
    "        state = {\n",
    "            \"user_input\": user_text,\n",
    "            \"tool_name\": \"\",\n",
    "            \"result\": \"\",\n",
    "            \"history\": history.copy()\n",
    "        }\n",
    "        for _ in range(3):  # Chaining rounds if needed\n",
    "            state = graph.invoke(state)\n",
    "            history.append(f\"Q: {state['user_input']}\")\n",
    "            history.append(f\"A: {state['result']}\")\n",
    "            break\n",
    "        log(\"\\n🧠 [Final Output]\")\n",
    "        log(f\"🔧 Selected Tool: {state['tool_name']}\")\n",
    "        log(f\"✅ Result: {state['result']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unit_agent_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73804efd-3348-4adb-b47e-3df965b82455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
