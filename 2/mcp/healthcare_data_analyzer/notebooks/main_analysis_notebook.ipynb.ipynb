{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25dc2ce1-ae27-44d3-8d48-229f738710c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modules imported successfully\n",
      "ğŸ”„ Initializing free local models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1f926f1e7e40ad9b7cc37c3354485a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1c083114c14df899f489a62f1f7b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccdd392feef404d845b9552f2b5e277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b89f3c3ecfb4b12a8788ee58a55114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1090f2d01a44998b8ab156e9468780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4384387c3974d7ebe9defd8a442e90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b690109bc5740a6af75c1446fc4d559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Free text generator loaded successfully!\n",
      "âœ… Free Data Processor initialized\n",
      "âœ… Analyzer and processor initialized\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_path = r'D:\\agenic_arhitecture\\mcp\\healthcare_data_analyzer\\agents'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from csv_analyzer_agent import FreeCSVAnalyzer\n",
    "from data_processor import FreeDataProcessor\n",
    "\n",
    "print(\"âœ… Modules imported successfully\")\n",
    "\n",
    "analyzer = FreeCSVAnalyzer()\n",
    "processor = FreeDataProcessor()\n",
    "\n",
    "print(\"âœ… Analyzer and processor initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a233f290-5812-45d1-be7e-830143424bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Creating sample healthcare tweet data for testing...\n",
      "âœ… Sample data created at D:\\agenic_arhitecture\\mcp\\data\\sample_healthcare_tweets.csv\n",
      "\n",
      "ğŸ“‚ Loading data file: D:\\agenic_arhitecture\\mcp\\data\\sample_healthcare_tweets.csv\n",
      "âœ… CSV loaded successfully with utf-8 encoding\n",
      "ğŸ§¹ Data cleaned: (1000, 6) â†’ (1000, 6)\n",
      "âœ… Data loaded; shape: (1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity_of_tweet</th>\n",
       "      <th>id_of_the_tweet</th>\n",
       "      <th>date_of_the_tweet</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text_of_the_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>user_090</td>\n",
       "      <td>Sample tweet 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000001</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>user_061</td>\n",
       "      <td>Sample tweet 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000002</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>user_077</td>\n",
       "      <td>Sample tweet 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1000003</td>\n",
       "      <td>2024-01-01 06:00:00</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>user_015</td>\n",
       "      <td>Sample tweet 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1000004</td>\n",
       "      <td>2024-01-01 08:00:00</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>user_024</td>\n",
       "      <td>Sample tweet 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity_of_tweet  id_of_the_tweet   date_of_the_tweet     query      user  \\\n",
       "0                  4          1000000 2024-01-01 00:00:00  NO_QUERY  user_090   \n",
       "1                  0          1000001 2024-01-01 02:00:00  NO_QUERY  user_061   \n",
       "2                  2          1000002 2024-01-01 04:00:00  NO_QUERY  user_077   \n",
       "3                  2          1000003 2024-01-01 06:00:00  NO_QUERY  user_015   \n",
       "4                  2          1000004 2024-01-01 08:00:00  NO_QUERY  user_024   \n",
       "\n",
       "  text_of_the_tweet  \n",
       "0    Sample tweet 0  \n",
       "1    Sample tweet 1  \n",
       "2    Sample tweet 2  \n",
       "3    Sample tweet 3  \n",
       "4    Sample tweet 4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = r'D:\\agenic_arhitecture\\mcp\\data\\your_data_file.csv'\n",
    "\n",
    "create_sample = True  # Set false and update file_path to use your own CSV\n",
    "\n",
    "if create_sample:\n",
    "    print(\"ğŸ”§ Creating sample healthcare tweet data for testing...\")\n",
    "    n_records = 1000\n",
    "    users = [f'user_{i:03d}' for i in range(100)]\n",
    "    sample_data = {\n",
    "        'polarity_of_tweet': np.random.choice([0, 2, 4], n_records),\n",
    "        'id_of_the_tweet': range(1000000, 1000000 + n_records),\n",
    "        'date_of_the_tweet': pd.date_range('2024-01-01', periods=n_records, freq='2H'),\n",
    "        'query': ['NO_QUERY'] * n_records,\n",
    "        'user': np.random.choice(users, n_records),\n",
    "        'text_of_the_tweet': [f'Sample tweet {i}' for i in range(n_records)]\n",
    "    }\n",
    "    df_sample = pd.DataFrame(sample_data)\n",
    "    os.makedirs(r'D:\\agenic_arhitecture\\mcp\\data', exist_ok=True)\n",
    "    sample_path = r'D:\\agenic_arhitecture\\mcp\\data\\sample_healthcare_tweets.csv'\n",
    "    df_sample.to_csv(sample_path, index=False)\n",
    "    file_path = sample_path\n",
    "    print(f\"âœ… Sample data created at {sample_path}\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ Loading data file: {file_path}\")\n",
    "result = processor.process_file(file_path)\n",
    "\n",
    "if result.get('success'):\n",
    "    df = result['dataframe']\n",
    "    print(f\"âœ… Data loaded; shape: {df.shape}\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f\"âŒ Failed to load data: {result.get('error')}\")\n",
    "    df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27bb12d-11b1-469d-93fd-2959c8951f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Running analysis for query: What's the max count of tweets per user per day\n",
      "âœ… File loaded with utf-8 encoding\n",
      "ğŸ“Š Analysis Results:\n",
      "1. ğŸ“ˆ Maximum tweets per user per day: 3\n",
      "2. ğŸ‘¥ Users with maximum tweets on specific days:\n",
      "3.   â€¢ user_032 on 2024-03-01: 3 tweets\n",
      "4.   â€¢ user_066 on 2024-03-23: 3 tweets\n",
      "5. ğŸ“Š Total users: 100\n",
      "6. ğŸ“Š Total tweets: 1000\n",
      "7. ğŸ“Š Average tweets per user: 10.00\n",
      "\n",
      "ğŸ’» Generated Python code:\n",
      "\n",
      "# Generated code for analysis: What's the max count of tweets per user per day\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Load the CSV file (update path as needed)\n",
      "df = pd.read_csv('your_file.csv', encoding='utf-8')\n",
      "\n",
      "# Basic information\n",
      "print(\"ğŸ“Š Dataset shape:\", df.shape)\n",
      "print(\"ğŸ“Š Columns:\", df.columns.tolist())\n",
      "print(\"ğŸ“Š Data types:\")\n",
      "print(df.dtypes)\n",
      "\n",
      "# Analysis based on your query\n",
      "\n",
      "# Tweet analysis: Find max tweets per user per day\n",
      "if 'user' in df.columns:\n",
      "    # Find date column\n",
      "    date_col = None\n",
      "    for col in df.columns:\n",
      "        if 'date' in col.lower():\n",
      "            date_col = col\n",
      "            break\n",
      "    \n",
      "    if date_col:\n",
      "        # Convert to datetime and group\n",
      "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
      "        df['date_only'] = df[date_col].dt.date\n",
      "        \n",
      "        # Count tweets per user per day\n",
      "        daily_counts = df.groupby(['user', 'date_only']).size()\n",
      "        max_tweets = daily_counts.max()\n",
      "        \n",
      "        print(f\"ğŸ“ˆ Maximum tweets per user per day: {max_tweets}\")\n",
      "        \n",
      "        # Show top users\n",
      "        max_users = daily_counts[daily_counts == max_tweets]\n",
      "        print(\"ğŸ‘¥ Users with maximum tweets:\")\n",
      "        for (user, date), count in max_users.head(10).items():\n",
      "            print(f\"  â€¢ {user} on {date}: {count} tweets\")\n",
      "\n",
      "# Display first few rows\n",
      "print(\"\\nğŸ“‹ Sample data:\")\n",
      "print(df.head())\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='font-family: Arial, sans-serif;'><h2>ğŸ“Š Analysis Results</h2><p><strong>ğŸ“ˆ Maximum tweets per user per day: 3</strong></p><p><strong>ğŸ‘¥ Users with maximum tweets on specific days:</strong></p><p style='margin-left: 20px;'>  â€¢ user_032 on 2024-03-01: 3 tweets</p><p style='margin-left: 20px;'>  â€¢ user_066 on 2024-03-23: 3 tweets</p><p><strong>ğŸ“Š Total users: 100</strong></p><p><strong>ğŸ“Š Total tweets: 1000</strong></p><p><strong>ğŸ“Š Average tweets per user: 10.00</strong></p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df is not None:\n",
    "    user_query = \"What's the max count of tweets per user per day\"\n",
    "    print(f\"ğŸ¤– Running analysis for query: {user_query}\")\n",
    "\n",
    "    analysis_result = analyzer.analyze_csv(file_path, user_query)\n",
    "    if analysis_result['success']:\n",
    "        print(\"ğŸ“Š Analysis Results:\")\n",
    "        for i, insight in enumerate(analysis_result['analysis'], 1):\n",
    "            print(f\"{i}. {insight}\")\n",
    "\n",
    "        print(\"\\nğŸ’» Generated Python code:\")\n",
    "        print(analysis_result['code'])\n",
    "\n",
    "        if 'html_output' in analysis_result:\n",
    "            display(HTML(analysis_result['html_output']))\n",
    "    else:\n",
    "        print(f\"âŒ Analysis failed: {analysis_result['error']}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data loaded, skipping analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9329a4c6-050a-42e2-8e1a-ab59c949db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Max tweets per user per day: 3\n",
      "ğŸ‘¥ Users with max tweets:\n",
      " - user_032 on 2024-03-01: 3 tweets\n",
      " - user_066 on 2024-03-23: 3 tweets\n"
     ]
    }
   ],
   "source": [
    "def analyze_healthcare_tweets(df):\n",
    "    if df is None:\n",
    "        print(\"âŒ No data for analysis.\")\n",
    "        return\n",
    "\n",
    "    user_col = next((c for c in df.columns if 'user' in c.lower()), None)\n",
    "    date_col = next((c for c in df.columns if 'date' in c.lower()), None)\n",
    "\n",
    "    if user_col and date_col:\n",
    "        df['date_processed'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df['date_only'] = df['date_processed'].dt.date\n",
    "\n",
    "        daily_counts = df.groupby([user_col, 'date_only']).size()\n",
    "        max_tweets = daily_counts.max()\n",
    "        max_users = daily_counts[daily_counts == max_tweets]\n",
    "\n",
    "        print(f\"ğŸ“ˆ Max tweets per user per day: {max_tweets}\")\n",
    "        print(\"ğŸ‘¥ Users with max tweets:\")\n",
    "        for (user, date), count in max_users.head(10).items():\n",
    "            print(f\" - {user} on {date}: {count} tweets\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Missing columns for tweet analysis. Found:\", df.columns.tolist())\n",
    "\n",
    "if df is not None:\n",
    "    analyze_healthcare_tweets(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9cd77-f3b7-4178-b1b8-41316f031db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
